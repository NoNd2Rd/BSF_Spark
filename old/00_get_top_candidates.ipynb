{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bde04c-aacd-43a9-ab71-6dacb5c46880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jupyter/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jupyter/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-3a82f7e8-b807-45f1-98ad-9e6e877aade2;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.0.0rc1 in spark-list\n",
      "\tfound io.delta#delta-storage;3.0.0rc1 in spark-list\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in spark-list\n",
      ":: resolution report :: resolve 572ms :: artifacts dl 20ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.0.0rc1 from spark-list in [default]\n",
      "\tio.delta#delta-storage;3.0.0rc1 from spark-list in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from spark-list in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-3a82f7e8-b807-45f1-98ad-9e6e877aade2\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/11ms)\n",
      "25/09/14 19:39:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Spark] Started 'bsf_candidates_analysis' log_level=WARN (effective=WARN), progress=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/14 19:40:30 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/09/14 19:40:30 WARN HiveConf: HiveConf of name hive.metastore.client.connect.timeout does not exist\n",
      "25/09/14 19:40:30 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/09/14 19:40:31 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/09/14 19:40:31 WARN HiveConf: HiveConf of name hive.metastore.client.connect.timeout does not exist\n",
      "25/09/14 19:40:31 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/09/14 19:40:34 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/09/14 19:40:34 WARN HiveConf: HiveConf of name hive.metastore.client.connect.timeout does not exist\n",
      "25/09/14 19:40:34 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/09/14 19:40:38 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|Action|count  |\n",
      "+------+-------+\n",
      "|Hold  |1304346|\n",
      "|Buy   |295321 |\n",
      "|Sell  |237073 |\n",
      "+------+-------+\n",
      "\n",
      "+---------+------+------+\n",
      "|TimeFrame|Action|count |\n",
      "+---------+------+------+\n",
      "|Daily    |Hold  |322321|\n",
      "|Daily    |Buy   |77109 |\n",
      "|Daily    |Sell  |59755 |\n",
      "|Long     |Hold  |336220|\n",
      "|Long     |Buy   |68103 |\n",
      "|Long     |Sell  |54862 |\n",
      "|Short    |Hold  |323472|\n",
      "|Short    |Buy   |74652 |\n",
      "|Short    |Sell  |61061 |\n",
      "|Swing    |Hold  |322333|\n",
      "|Swing    |Buy   |75457 |\n",
      "|Swing    |Sell  |61395 |\n",
      "+---------+------+------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/14 19:44:00 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stage 0 completed: Top 20 candidates selected per timeframe\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, max as spark_max\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "import pandas as pd\n",
    "from bsf_env import init_spark, init_mariadb_engine,set_spark_verbosity\n",
    "from pyspark.sql.functions import lit, current_timestamp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display, HTML\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import joblib\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "spark = init_spark(\"bsf_candidates_analysis\", log_level=\"WARN\", show_progress=False, enable_ui=True, priority=False)\n",
    "engine = init_mariadb_engine()\n",
    "\n",
    "ingest_ts = spark.sql(\"SELECT current_timestamp()\").collect()[0][0]\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.width\", 200)         # Adjust width for readability\n",
    "pd.set_option(\"display.max_rows\", 20)       # Show only top 20 rows by default\n",
    "\n",
    "# -----------------------------\n",
    "# STAGE 0: Select top 20 candidates per timeframe\n",
    "# -----------------------------\n",
    "top_n = 20\n",
    "df_last = spark.table(\"bsf.daily_signals_last_allcol \")\n",
    "df_all = spark.table(\"bsf.daily_signals\")\n",
    "\n",
    "df_all.groupBy(\"Action\").count().orderBy(F.desc(\"count\")).show(truncate=False)\n",
    "\n",
    "print(df_all.groupBy(\"TimeFrame\", \"Action\") \\\n",
    "  .count() \\\n",
    "  .orderBy(\"TimeFrame\", F.desc(\"count\")) \\\n",
    "  .show(truncate=False))\n",
    "\n",
    "df = df_last.cache()\n",
    "\n",
    "# df_last = spark.table(\"bsf.daily_signals_last_allcol\")\n",
    "# df_all = spark.table(\"bsf.daily_signals\")\n",
    "df = df_last.cache()\n",
    "\n",
    "# Aggregate Buy/Sell/Hold counts per company per timeframe\n",
    "df_counts = df.groupBy(\"CompanyId\", \"TimeFrame\").agg(\n",
    "    F.sum(F.when(F.col(\"Action\") == \"Buy\", 1).otherwise(0)).alias(\"BuyCount\"),\n",
    "    F.sum(F.when(F.col(\"Action\") == \"Sell\", 1).otherwise(0)).alias(\"SellCount\"),\n",
    "    F.sum(F.when(F.col(\"Action\") == \"Hold\", 1).otherwise(0)).alias(\"HoldCount\"),\n",
    "    F.sum(\"Return\").alias(\"Return\")\n",
    ")\n",
    "\n",
    "# Define window partitioned by timeframe for ranking\n",
    "w_buy = Window.partitionBy(\"TimeFrame\").orderBy(F.desc(\"BuyCount\"))\n",
    "w_sell = Window.partitionBy(\"TimeFrame\").orderBy(F.desc(\"SellCount\"))\n",
    "w_hold = Window.partitionBy(\"TimeFrame\").orderBy(F.desc(\"HoldCount\"))\n",
    "\n",
    "# Add separate rank columns\n",
    "df_ranked = (\n",
    "    df_counts\n",
    "    .withColumn(\"BuyRank\", F.row_number().over(w_buy))\n",
    "    .withColumn(\"SellRank\", F.row_number().over(w_sell))\n",
    "    .withColumn(\"HoldRank\", F.row_number().over(w_hold))\n",
    ")\n",
    "\n",
    "# Select top 20 per timeframe using BuyRank (or adjust metric)\n",
    "top_candidates_ranked = df_ranked.filter(F.col(\"BuyRank\") <= top_n)\n",
    "\n",
    "# Join back to original df to get full rows for these top candidates\n",
    "top_candidates_df = df.join(top_candidates_ranked, on=[\"CompanyId\",\"TimeFrame\"], how=\"inner\")\n",
    "\n",
    "# Convert to Pandas for Stage 1 regression\n",
    "timeframes = [\"Short\", \"Swing\", \"Long\", \"Daily\"]\n",
    "timeframe_dfs = {tf: top_candidates_df.filter(F.col(\"TimeFrame\") == tf) for tf in timeframes}\n",
    "timeframe_dfs_all = {tf: df_all.filter(F.col(\"TimeFrame\") == tf) for tf in timeframes}\n",
    "\n",
    "# Optional: convert to Pandas for regression\n",
    "pdf_timeframe_dfs = {tf: timeframe_dfs[tf].toPandas() for tf in timeframes}\n",
    "pdf_timeframe_dfs_all = {tf: timeframe_dfs_all[tf].toPandas() for tf in timeframes}\n",
    "\n",
    "print(\"✅ Stage 0 completed: Top 20 candidates selected per timeframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d2ff8-0a26-4d25-a565-835c391f1361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72490c20-d122-4e0d-a864-4b20402074b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/14 20:48:40 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "25/09/14 20:48:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.errors.SparkCoreErrors$.clusterSchedulerError(SparkCoreErrors.scala:291)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:978)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:165)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:263)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:170)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "top_n = 5\n",
    "forecast_steps_map = {\n",
    "    \"Daily\": 1,\n",
    "    \"Short\": 3,\n",
    "    \"Swing\": 5,\n",
    "    \"Long\": 10\n",
    "}\n",
    "epsilon = 1e-6  # for log transform if needed\n",
    "\n",
    "# -------------------------\n",
    "# INIT SPARK\n",
    "# -------------------------\n",
    "spark = SparkSession.builder.appName(\"Stage1_Ensemble_Stage2_SARIMAX\").getOrCreate()\n",
    "\n",
    "# Assume timeframe_dfs_all is a dict of Spark DataFrames keyed by timeframe\n",
    "# e.g., timeframe_dfs_all = {\"Short\": sdf_short, \"Swing\": sdf_swing, ...}\n",
    "\n",
    "# -------------------------\n",
    "# STAGE 1: Fast Ensemble Regression (Linear + Lasso + Ridge)\n",
    "# -------------------------\n",
    "all_stage1_predictions = []\n",
    "\n",
    "for tf, sdf_tf in timeframe_dfs_all.items():\n",
    "    pdf_tf = sdf_tf.toPandas()\n",
    "    print(f\"\\n=== Stage 1: Processing timeframe: {tf} ===\")\n",
    "\n",
    "    for cid in pdf_tf['CompanyId'].unique():\n",
    "        df_c = pdf_tf[pdf_tf['CompanyId'] == cid].copy()\n",
    "\n",
    "        # Training rows\n",
    "        train_df = df_c[df_c['TomorrowClose'].notna()].copy()\n",
    "        if train_df.empty:\n",
    "            continue\n",
    "\n",
    "        # Numeric features excluding target\n",
    "        numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if 'TomorrowClose' in numeric_cols:\n",
    "            numeric_cols.remove('TomorrowClose')\n",
    "\n",
    "        # Minimal correlation filter\n",
    "        corr = train_df[numeric_cols + ['TomorrowClose']].corr()['TomorrowClose'].abs()\n",
    "        good_features = corr[corr >= 0.03].index.tolist()\n",
    "        good_features = [f for f in good_features if f != 'TomorrowClose']\n",
    "\n",
    "        if not good_features:\n",
    "            continue\n",
    "\n",
    "        X_train = train_df[good_features].fillna(0)\n",
    "        y_train = train_df['TomorrowClose']\n",
    "\n",
    "        # Ensemble regressions\n",
    "        lr_model = LinearRegression().fit(X_train, y_train)\n",
    "        lasso_model = Lasso(alpha=0.01).fit(X_train, y_train)\n",
    "        ridge_model = Ridge(alpha=1.0, solver=\"svd\").fit(X_train, y_train)\n",
    "\n",
    "        # Predict future rows\n",
    "        future_df = df_c[df_c['TomorrowClose'].isna()].copy()\n",
    "        if not future_df.empty:\n",
    "            X_future = future_df[good_features].fillna(0)\n",
    "            future_df['Pred_Linear'] = lr_model.predict(X_future)\n",
    "            future_df['Pred_Lasso'] = lasso_model.predict(X_future)\n",
    "            future_df['Pred_Ridge'] = ridge_model.predict(X_future)\n",
    "\n",
    "            # Ensemble average\n",
    "            future_df['Pred_Ensemble'] = future_df[['Pred_Linear', 'Pred_Lasso', 'Pred_Ridge']].mean(axis=1)\n",
    "\n",
    "            future_df['TimeFrame'] = tf\n",
    "            future_df['CompanyId'] = cid\n",
    "            all_stage1_predictions.append(future_df)\n",
    "\n",
    "# Combine predictions\n",
    "if all_stage1_predictions:\n",
    "    stage1_df = pd.concat(all_stage1_predictions, ignore_index=True)\n",
    "else:\n",
    "    stage1_df = pd.DataFrame()\n",
    "    print(\"⚠️ No Stage 1 predictions generated.\")\n",
    "\n",
    "# -------------------------\n",
    "# Select top-N candidates per timeframe (ensemble)\n",
    "# -------------------------\n",
    "def select_top_n(df, pred_col='Pred_Ensemble', n=top_n):\n",
    "    top_list = []\n",
    "    for tf in df['TimeFrame'].unique():\n",
    "        tf_df = df[df['TimeFrame'] == tf].copy()\n",
    "        tf_df = tf_df.sort_values(pred_col, ascending=False)\n",
    "        top_list.append(tf_df.head(n))\n",
    "    return pd.concat(top_list, ignore_index=True) if top_list else pd.DataFrame()\n",
    "\n",
    "stage1_top_df = select_top_n(stage1_df, pred_col='Pred_Ensemble', n=top_n)\n",
    "print(\"\\n=== Stage 1 Top Candidates per Timeframe (Ensemble) ===\")\n",
    "print(stage1_top_df[['TimeFrame', 'CompanyId', 'Pred_Ensemble']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5110ecba-16b1-403d-9951-7d0edf0c4ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ SARIMAX failed for 82853-Daily: Seasonal periodicity must be greater than 1.\n",
      "❌ SARIMAX failed for 34193-Daily: Seasonal periodicity must be greater than 1.\n",
      "❌ SARIMAX failed for 292453-Daily: Seasonal periodicity must be greater than 1.\n",
      "❌ SARIMAX failed for 240168-Daily: Seasonal periodicity must be greater than 1.\n",
      "❌ SARIMAX failed for 53081-Daily: Seasonal periodicity must be greater than 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/jupyter/.venv/python3.9_bsf/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# STAGE 2: SARIMAX on top candidates\n",
    "# -------------------------\n",
    "sarimax_results = []\n",
    "\n",
    "# Define simple SARIMAX orders per timeframe\n",
    "sarimax_orders = {\n",
    "    \"Daily\": (1,1,1,1),\n",
    "    \"Short\": (1,1,1,3),\n",
    "    \"Swing\": (1,1,1,5),\n",
    "    \"Long\": (1,1,1,7)\n",
    "}\n",
    "\n",
    "for tf, steps in forecast_steps_map.items():\n",
    "    df_tf = timeframe_dfs_all[tf].toPandas().copy()\n",
    "    top_companies = stage1_top_df.loc[stage1_top_df['TimeFrame'] == tf, 'CompanyId'].unique()\n",
    "\n",
    "    for cid in top_companies:\n",
    "        df_c = df_tf[df_tf['CompanyId'] == cid].copy().dropna(subset=['TomorrowReturn'])\n",
    "        if len(df_c) < 30:\n",
    "            print(f\"⏭️ Skipping {cid}-{tf} (not enough data)\")\n",
    "            continue\n",
    "\n",
    "        ts = df_c['TomorrowReturn']\n",
    "        p,d,q,s = sarimax_orders[tf]\n",
    "\n",
    "        try:\n",
    "            model = SARIMAX(\n",
    "                ts,\n",
    "                order=(p,d,q),\n",
    "                seasonal_order=(0,1,1,s),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            fit = model.fit(disp=False)\n",
    "            forecast = fit.get_forecast(steps=steps)\n",
    "            mean_pred = forecast.predicted_mean.mean()\n",
    "\n",
    "            sarimax_results.append({\n",
    "                'CompanyId': cid,\n",
    "                'TimeFrame': tf,\n",
    "                'Pred_SARIMAX': float(mean_pred),\n",
    "                'order': str((p,d,q)),\n",
    "                'seasonal_order': str((0,1,1,s))\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"❌ SARIMAX failed for {cid}-{tf}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sarimax_df = pd.DataFrame(sarimax_results)\n",
    "final_df = stage1_top_df.merge(sarimax_df, on=['CompanyId','TimeFrame'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cdd519-5fad-43e9-9397-562fb24fa391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/14 20:04:41 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `spark_catalog`.`bsf`.`final_top_candidates` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n",
      "25/09/14 20:04:42 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "25/09/14 20:04:44 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "25/09/14 20:04:44 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/09/14 20:04:44 WARN HiveConf: HiveConf of name hive.metastore.client.connect.timeout does not exist\n",
      "25/09/14 20:04:44 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Failed to merge fields 'CompanyId' and 'CompanyId'. Failed to merge incompatible data types StringType and LongType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Add run_id and write\u001b[39;00m\n\u001b[1;32m     26\u001b[0m top_out_df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(top_out)\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, lit(run_id))\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtop_out_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveAsTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Stage 2 run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m written to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m top_out_df\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.venv/python3.9_bsf/lib/python3.9/site-packages/pyspark/sql/readwriter.py:1521\u001b[0m, in \u001b[0;36mDataFrameWriter.saveAsTable\u001b[0;34m(self, name, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m-> 1521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveAsTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/python3.9_bsf/lib/python3.9/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.venv/python3.9_bsf/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Failed to merge fields 'CompanyId' and 'CompanyId'. Failed to merge incompatible data types StringType and LongType"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Write top candidates to Delta\n",
    "# -------------------------\n",
    "top_out = final_df[['CompanyId', 'TimeFrame', 'Pred_Ensemble', 'Pred_SARIMAX']].copy()\n",
    "\n",
    "table_name = \"bsf.final_top_candidates\"\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    CompanyId STRING,\n",
    "    TimeFrame STRING,\n",
    "    Pred_Ensemble DOUBLE,\n",
    "    Pred_SARIMAX DOUBLE,\n",
    "    run_id INT\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "# Determine next run_id\n",
    "if spark._jsparkSession.catalog().tableExists(table_name):\n",
    "    latest_run_id = spark.read.table(table_name).agg(spark_max(\"run_id\")).collect()[0][0]\n",
    "    run_id = (latest_run_id or 0) + 1\n",
    "else:\n",
    "    run_id = 1\n",
    "\n",
    "# Add run_id and write\n",
    "top_out_df = spark.createDataFrame(top_out).withColumn(\"run_id\", lit(run_id))\n",
    "top_out_df.write.format(\"delta\").mode(\"append\").saveAsTable(table_name)\n",
    "\n",
    "print(f\"✅ Stage 2 run {run_id} written to {table_name}\")\n",
    "top_out_df.show()\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BSF (3.9)",
   "language": "python",
   "name": "python3.9_bsf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
